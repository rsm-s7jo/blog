<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.5">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sunghoon Jo">
<meta name="dcterms.date" content="2025-05-27">

<title>Multinomial Logit Model – Sunghoon’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-ff4371ef257df69894857e99c6ad0d06.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-8721af47cae544f845bd8d7220388c47.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Sunghoon’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../index.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">Resume</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#likelihood-for-the-multi-nomial-logit-mnl-model" id="toc-likelihood-for-the-multi-nomial-logit-mnl-model" class="nav-link active" data-scroll-target="#likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</a></li>
  <li><a href="#simulate-conjoint-data" id="toc-simulate-conjoint-data" class="nav-link" data-scroll-target="#simulate-conjoint-data">2. Simulate Conjoint Data</a></li>
  <li><a href="#preparing-the-data-for-estimation" id="toc-preparing-the-data-for-estimation" class="nav-link" data-scroll-target="#preparing-the-data-for-estimation">3. Preparing the Data for Estimation</a></li>
  <li><a href="#estimation-via-maximum-likelihood" id="toc-estimation-via-maximum-likelihood" class="nav-link" data-scroll-target="#estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</a></li>
  <li><a href="#estimation-via-bayesian-methods" id="toc-estimation-via-bayesian-methods" class="nav-link" data-scroll-target="#estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</a></li>
  <li><a href="#discussion" id="toc-discussion" class="nav-link" data-scroll-target="#discussion">6. Discussion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Multinomial Logit Model</h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Sunghoon Jo </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">May 27, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="likelihood-for-the-multi-nomial-logit-mnl-model" class="level2">
<h2 class="anchored" data-anchor-id="likelihood-for-the-multi-nomial-logit-mnl-model">1. Likelihood for the Multi-nomial Logit (MNL) Model</h2>
<p>Suppose we have <span class="math inline">\(i=1,\ldots,n\)</span> consumers who each select exactly one product <span class="math inline">\(j\)</span> from a set of <span class="math inline">\(J\)</span> products. The outcome variable is the identity of the product chosen <span class="math inline">\(y_i \in \{1, \ldots, J\}\)</span> or equivalently a vector of <span class="math inline">\(J-1\)</span> zeros and <span class="math inline">\(1\)</span> one, where the <span class="math inline">\(1\)</span> indicates the selected product. For example, if the third product was chosen out of 3 products, then either <span class="math inline">\(y=3\)</span> or <span class="math inline">\(y=(0,0,1)\)</span> depending on how we want to represent it. Suppose also that we have a vector of data on each product <span class="math inline">\(x_j\)</span> (eg, brand, price, etc.).</p>
<p>We model the consumer’s decision as the selection of the product that provides the most utility, and we’ll specify the utility function as a linear function of the product characteristics:</p>
<p><span class="math display">\[ U_{ij} = x_j'\beta + \epsilon_{ij} \]</span></p>
<p>where <span class="math inline">\(\epsilon_{ij}\)</span> is an i.i.d. extreme value error term.</p>
<p>The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer <span class="math inline">\(i\)</span> chooses product <span class="math inline">\(j\)</span>:</p>
<p><span class="math display">\[ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} \]</span></p>
<p>For example, if there are 3 products, the probability that consumer <span class="math inline">\(i\)</span> chooses product 3 is:</p>
<p><span class="math display">\[ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta}} \]</span></p>
<p>A clever way to write the individual likelihood function for consumer <span class="math inline">\(i\)</span> is the product of the <span class="math inline">\(J\)</span> probabilities, each raised to the power of an indicator variable (<span class="math inline">\(\delta_{ij}\)</span>) that indicates the chosen product:</p>
<p><span class="math display">\[ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}\]</span></p>
<p>Notice that if the consumer selected product <span class="math inline">\(j=3\)</span>, then <span class="math inline">\(\delta_{i3}=1\)</span> while <span class="math inline">\(\delta_{i1}=\delta_{i2}=0\)</span> and the likelihood is:</p>
<p><span class="math display">\[ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^3e^{x_k'\beta}} \]</span></p>
<p>The joint likelihood (across all consumers) is the product of the <span class="math inline">\(n\)</span> individual likelihoods:</p>
<p><span class="math display">\[ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} \]</span></p>
<p>And the joint log-likelihood function is:</p>
<p><span class="math display">\[ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) \]</span></p>
</section>
<section id="simulate-conjoint-data" class="level2">
<h2 class="anchored" data-anchor-id="simulate-conjoint-data">2. Simulate Conjoint Data</h2>
<p>We will simulate data from a conjoint experiment about video content streaming services. We elect to simulate 100 respondents, each completing 10 choice tasks, where they choose from three alternatives per task. For simplicity, there is not a “no choice” option; each simulated respondent must select one of the 3 alternatives.</p>
<p>Each alternative is a hypothetical streaming offer consistent of three attributes: (1) brand is either Netflix, Amazon Prime, or Hulu; (2) ads can either be part of the experience, or it can be ad-free, and (3) price per month ranges from $4 to $32 in increments of $4.</p>
<p>The part-worths (ie, preference weights or beta parameters) for the attribute levels will be 1.0 for Netflix, 0.5 for Amazon Prime (with 0 for Hulu as the reference brand); -0.8 for included adverstisements (0 for ad-free); and -0.1*price so that utility to consumer <span class="math inline">\(i\)</span> for hypothethical streaming service <span class="math inline">\(j\)</span> is</p>
<p><span class="math display">\[
u_{ij} = (1 \times Netflix_j) + (0.5 \times Prime_j) + (-0.8*Ads_j) - 0.1\times Price_j + \varepsilon_{ij}
\]</span></p>
<p>where the variables are binary indicators and <span class="math inline">\(\varepsilon\)</span> is Type 1 Extreme Value (ie, Gumble) distributed.</p>
<p>The following code provides the simulation of the conjoint data.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<div id="e3f9b55e" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Set seed for reproducibility</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">123</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>random.seed(<span class="dv">123</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Define attributes</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>brand <span class="op">=</span> [<span class="st">"N"</span>, <span class="st">"P"</span>, <span class="st">"H"</span>] <span class="co"># Netflix, Prime, Hulu</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>ad <span class="op">=</span> [<span class="st">"Yes"</span>, <span class="st">"No"</span>]</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co"># R's seq(8, 32, by=4) is a sequence from 8 to 32 incrementing by 4</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>price <span class="op">=</span> np.arange(<span class="dv">8</span>, <span class="dv">33</span>, <span class="dv">4</span>) <span class="co"># 33 is exclusive, so it goes up to 32</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate all possible profiles</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent to R's expand.grid</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>profiles <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(product(brand, ad, price)), columns<span class="op">=</span>[<span class="st">'brand'</span>, <span class="st">'ad'</span>, <span class="st">'price'</span>])</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>m <span class="op">=</span> <span class="bu">len</span>(profiles) <span class="co"># Number of rows in profiles</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Assign part-worth utilities (true parameters)</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>b_util <span class="op">=</span> {<span class="st">"N"</span>: <span class="fl">1.0</span>, <span class="st">"P"</span>: <span class="fl">0.5</span>, <span class="st">"H"</span>: <span class="dv">0</span>}</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>a_util <span class="op">=</span> {<span class="st">"Yes"</span>: <span class="op">-</span><span class="fl">0.8</span>, <span class="st">"No"</span>: <span class="fl">0.0</span>}</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>p_util <span class="op">=</span> <span class="kw">lambda</span> p: <span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> p</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of respondents, choice tasks, and alternatives per task</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>n_peeps <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>n_tasks <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>n_alts <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Function to simulate one respondent’s data</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sim_one(<span class="bu">id</span>):</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    datlist <span class="op">=</span> []</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Loop over choice tasks</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> t <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_tasks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Randomly sample 3 alternatives (better practice would be to use a design)</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Equivalent to R's profiles[sample(m, size=n_alts), ]</span></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>        sampled_indices <span class="op">=</span> random.sample(<span class="bu">range</span>(m), k<span class="op">=</span>n_alts)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>        dat <span class="op">=</span> profiles.iloc[sampled_indices].copy() <span class="co"># Use .copy() to avoid SettingWithCopyWarning</span></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add resp and task columns</span></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'resp'</span>] <span class="op">=</span> <span class="bu">id</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'task'</span>] <span class="op">=</span> t</span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Compute deterministic portion of utility</span></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Equivalent to R's b_util[dat$brand] + a_util[dat$ad] + p_util(dat$price)</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'v'</span>] <span class="op">=</span> dat.<span class="bu">apply</span>(<span class="kw">lambda</span> row: b_util[row[<span class="st">'brand'</span>]] <span class="op">+</span> a_util[row[<span class="st">'ad'</span>]] <span class="op">+</span> p_util(row[<span class="st">'price'</span>]), axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Add Gumbel noise (Type I extreme value)</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Equivalent to R's -log(-log(runif(n_alts)))</span></span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Using inverse transform sampling for Gumbel distribution from uniform(0,1)</span></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'e'</span>] <span class="op">=</span> <span class="op">-</span>np.log(<span class="op">-</span>np.log(np.random.rand(n_alts))) </span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'u'</span>] <span class="op">=</span> dat[<span class="st">'v'</span>] <span class="op">+</span> dat[<span class="st">'e'</span>]</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Identify chosen alternative</span></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Equivalent to R's as.integer(dat$u == max(dat$u))</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>        dat[<span class="st">'choice'</span>] <span class="op">=</span> (dat[<span class="st">'u'</span>] <span class="op">==</span> dat[<span class="st">'u'</span>].<span class="bu">max</span>()).astype(<span class="bu">int</span>)</span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Store task</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a>        datlist.append(dat)</span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine all tasks for one respondent</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Equivalent to R's do.call(rbind, datlist)</span></span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> pd.concat(datlist, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate data for all respondents</span></span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent to R's do.call(rbind, lapply(1:n_peeps, sim_one))</span></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a>conjoint_data_list <span class="op">=</span> [sim_one(i) <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_peeps <span class="op">+</span> <span class="dv">1</span>)]</span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.concat(conjoint_data_list, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove values unobservable to the researcher</span></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a><span class="co"># Equivalent to R's conjoint_data[ , c("resp", "task", "brand", "ad", "price", "choice")]</span></span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> conjoint_data.loc[:, [<span class="st">"resp"</span>, <span class="st">"task"</span>, <span class="st">"brand"</span>, <span class="st">"ad"</span>, <span class="st">"price"</span>, <span class="st">"choice"</span>]]</span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results</span></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Generated conjoint_data head:"</span>)</span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(conjoint_data.head())</span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">Generated conjoint_data info:"</span>)</span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a>conjoint_data.info()</span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">Total number of respondents: </span><span class="sc">{</span>conjoint_data[<span class="st">'resp'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total number of choice tasks (per respondent): </span><span class="sc">{</span>conjoint_data[<span class="st">'task'</span>]<span class="sc">.</span>nunique()<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total number of alternatives (per task): </span><span class="sc">{</span>conjoint_data<span class="sc">.</span>groupby([<span class="st">'resp'</span>, <span class="st">'task'</span>])<span class="sc">.</span>size()<span class="sc">.</span>mean()<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Generated conjoint_data head:
   resp  task brand   ad  price  choice
0     1     1     N  Yes     20       1
1     1     1     P  Yes     20       0
2     1     1     N  Yes     28       0
3     1     2     P   No     28       0
4     1     2     P  Yes     20       1

Generated conjoint_data info:
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 3000 entries, 0 to 2999
Data columns (total 6 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   resp    3000 non-null   int64 
 1   task    3000 non-null   int64 
 2   brand   3000 non-null   object
 3   ad      3000 non-null   object
 4   price   3000 non-null   int64 
 5   choice  3000 non-null   int64 
dtypes: int64(4), object(2)
memory usage: 140.8+ KB

Total number of respondents: 100
Total number of choice tasks (per respondent): 10
Total number of alternatives (per task): 3.0</code></pre>
</div>
</div>
</div>
</div>
</div>
</section>
<section id="preparing-the-data-for-estimation" class="level2">
<h2 class="anchored" data-anchor-id="preparing-the-data-for-estimation">3. Preparing the Data for Estimation</h2>
<p>The “hard part” of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer <span class="math inline">\(i\)</span>, covariate <span class="math inline">\(k\)</span>, and product <span class="math inline">\(j\)</span>) instead of the typical 2 dimensions for cross-sectional regression models (consumer <span class="math inline">\(i\)</span> and covariate <span class="math inline">\(k\)</span>). The fact that each task for each respondent has the same number of alternatives (3) helps. In addition, we need to convert the categorical variables for brand and ads into binary variables.</p>
<div id="453e8351" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>conjoint_data <span class="op">=</span> pd.read_csv(<span class="st">'conjoint_data.csv'</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create dummy variables for categorical attributes</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 'H' (Hulu) and 'No' (ad-free) are the reference categories in the utility function.</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co"># So, we will create dummies for 'N' (Netflix), 'P' (Prime), and 'Yes' (Ads).</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># pd.get_dummies will create columns like 'brand_N', 'brand_P', 'brand_H', 'ad_Yes', 'ad_No'.</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># We will then select and rename the specific columns that correspond to our beta parameters.</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>df_prep <span class="op">=</span> conjoint_data.copy()</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert 'brand' and 'ad' into dummy variables</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="co"># We will create all dummies first, then select the ones corresponding to the non-reference categories</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>df_prep <span class="op">=</span> pd.get_dummies(df_prep, columns<span class="op">=</span>[<span class="st">'brand'</span>, <span class="st">'ad'</span>], drop_first<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="co"># Rename the dummy columns to match the utility function's variable names</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="co"># For 'brand': 'N' -&gt; 'Netflix', 'P' -&gt; 'Prime'</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a><span class="co"># For 'ad': 'Yes' -&gt; 'Ads'</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>df_prep.rename(columns<span class="op">=</span>{</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>    <span class="st">'brand_N'</span>: <span class="st">'Netflix'</span>,</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="st">'brand_P'</span>: <span class="st">'Prime'</span>,</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="st">'ad_Yes'</span>: <span class="st">'Ads'</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>}, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Drop the reference category dummy variables as their coefficients are implicitly zero</span></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># and they should not be included in the X matrix for direct estimation.</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a><span class="co"># The original problem statement indicates 'Hulu' and 'Ad-free' as reference.</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>df_prep <span class="op">=</span> df_prep.drop(columns<span class="op">=</span>[<span class="st">'brand_H'</span>, <span class="st">'ad_No'</span>])</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Verify the prepared data structure</span></span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Prepared df_prep head (with dummy variables for estimation) ---"</span>)</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(df_prep.head())</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Prepared df_prep info ---"</span>)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>df_prep.info()</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a><span class="co"># Final check: Ensure the columns for estimation are present</span></span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a><span class="co"># We need 'Netflix', 'Prime', 'Ads', 'price', 'resp', 'task', 'choice'</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a><span class="co"># The columns 'resp' and 'task' are crucial for grouping alternatives within a choice set.</span></span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">df_prep DataFrame prepared for estimation."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Prepared df_prep head (with dummy variables for estimation) ---
      task  choice  price  Netflix  Prime   Ads
resp                                           
1        1       1     28     True  False  True
1        1       0     16    False  False  True
1        1       0     16    False   True  True
1        2       0     32     True  False  True
1        2       1     16    False   True  True

--- Prepared df_prep info ---
&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 3000 entries, 1 to 100
Data columns (total 6 columns):
 #   Column   Non-Null Count  Dtype
---  ------   --------------  -----
 0   task     3000 non-null   int64
 1   choice   3000 non-null   int64
 2   price    3000 non-null   int64
 3   Netflix  3000 non-null   bool 
 4   Prime    3000 non-null   bool 
 5   Ads      3000 non-null   bool 
dtypes: bool(3), int64(3)
memory usage: 102.5 KB

df_prep DataFrame prepared for estimation.</code></pre>
</div>
</div>
</section>
<section id="estimation-via-maximum-likelihood" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-maximum-likelihood">4. Estimation via Maximum Likelihood</h2>
<p>::::</p>
<div id="9633e671" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize <span class="co"># Import only the minimize function</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-likelihood function</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_vector: [beta_netflix, beta_prime, beta_ads, beta_price]</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnl_log_likelihood(beta_vector, data):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># IMPORTANT: Create a copy of the data to avoid modifying the original DataFrame</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># in subsequent calls by the optimizer.</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.copy()</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Extract relevant columns for the X matrix. Their order must match beta_vector.</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Expected column names in 'data': 'Netflix', 'Prime', 'Ads', 'price'</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> data[[<span class="st">'Netflix'</span>, <span class="st">'Prime'</span>, <span class="st">'Ads'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- CRITICAL FIX: Explicitly convert X to float64 type ---</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This ensures X is a proper float NumPy array for np.dot operation,</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    <span class="co"># preventing the 'float' object has no attribute 'exp' error.</span></span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.astype(np.float64)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># --- End of fix ---</span></span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate deterministic utility V_ij = x_j'beta</span></span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> np.dot(X, beta_vector)</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate exp(V) for all alternatives</span></span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>    <span class="co"># The previous error occurred because V was not a suitable NumPy array for np.exp.</span></span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Ensuring numeric types in df_prep and explicitly converting X should fix this.</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">'exp_V'</span>] <span class="op">=</span> np.exp(V)</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group by 'resp' and 'task' to get the sum of exp(V) for each choice set.</span></span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># This sum will serve as the denominator for the probabilities.</span></span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    sum_exp_V_per_task <span class="op">=</span> data.groupby([<span class="st">'resp'</span>, <span class="st">'task'</span>])[<span class="st">'exp_V'</span>].transform(<span class="st">'sum'</span>)</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate probabilities P_i(j) = exp(V_ij) / sum(exp(V_ik))</span></span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add a small constant (1e-9) to the denominator for numerical stability, to prevent division by zero.</span></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> data[<span class="st">'exp_V'</span>] <span class="op">/</span> (sum_exp_V_per_task <span class="op">+</span> <span class="fl">1e-9</span>)</span>
<span id="cb5-35"><a href="#cb5-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-36"><a href="#cb5-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate log-likelihood: sum_i sum_j (delta_ij * log(P_i(j)))</span></span>
<span id="cb5-37"><a href="#cb5-37" aria-hidden="true" tabindex="-1"></a>    <span class="co"># delta_ij is the 'choice' column (1 if chosen, 0 otherwise).</span></span>
<span id="cb5-38"><a href="#cb5-38" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Only terms where choice=1 will contribute to the sum.</span></span>
<span id="cb5-39"><a href="#cb5-39" aria-hidden="true" tabindex="-1"></a>    log_probabilities <span class="op">=</span> np.log(probabilities)</span>
<span id="cb5-40"><a href="#cb5-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-41"><a href="#cb5-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sum the log-probabilities for the chosen alternatives.</span></span>
<span id="cb5-42"><a href="#cb5-42" aria-hidden="true" tabindex="-1"></a>    total_log_likelihood <span class="op">=</span> np.<span class="bu">sum</span>(np.where(data[<span class="st">'choice'</span>] <span class="op">==</span> <span class="dv">1</span>, log_probabilities, <span class="dv">0</span>))</span>
<span id="cb5-43"><a href="#cb5-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-44"><a href="#cb5-44" aria-hidden="true" tabindex="-1"></a>    <span class="co"># We aim to maximize this likelihood, so for minimization, we return the negative log-likelihood.</span></span>
<span id="cb5-45"><a href="#cb5-45" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="op">-</span>total_log_likelihood</span>
<span id="cb5-46"><a href="#cb5-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-47"><a href="#cb5-47" aria-hidden="true" tabindex="-1"></a><span class="co"># --- MLE Estimation ---</span></span>
<span id="cb5-48"><a href="#cb5-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-49"><a href="#cb5-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial guess for beta parameters</span></span>
<span id="cb5-50"><a href="#cb5-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Order: [beta_netflix, beta_prime, beta_ads, beta_price]</span></span>
<span id="cb5-51"><a href="#cb5-51" aria-hidden="true" tabindex="-1"></a>initial_betas <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.05</span>], dtype<span class="op">=</span>np.float64) <span class="co"># Explicitly set dtype</span></span>
<span id="cb5-52"><a href="#cb5-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-53"><a href="#cb5-53" aria-hidden="true" tabindex="-1"></a><span class="co"># Optimize the negative log-likelihood function</span></span>
<span id="cb5-54"><a href="#cb5-54" aria-hidden="true" tabindex="-1"></a><span class="co"># 'args' passes additional arguments (our data, i.e., df_prep) to the log-likelihood function.</span></span>
<span id="cb5-55"><a href="#cb5-55" aria-hidden="true" tabindex="-1"></a>result <span class="op">=</span> minimize(mnl_log_likelihood, initial_betas, args<span class="op">=</span>(df_prep,), method<span class="op">=</span><span class="st">'BFGS'</span>) <span class="co"># BFGS is a good general-purpose optimizer.</span></span>
<span id="cb5-56"><a href="#cb5-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-57"><a href="#cb5-57" aria-hidden="true" tabindex="-1"></a><span class="co"># Print optimization results</span></span>
<span id="cb5-58"><a href="#cb5-58" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- MLE Optimization Results ---"</span>)</span>
<span id="cb5-59"><a href="#cb5-59" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(result)</span>
<span id="cb5-60"><a href="#cb5-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-61"><a href="#cb5-61" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract MLEs</span></span>
<span id="cb5-62"><a href="#cb5-62" aria-hidden="true" tabindex="-1"></a>mle_betas <span class="op">=</span> result.x</span>
<span id="cb5-63"><a href="#cb5-63" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">MLE Beta Parameters:"</span>)</span>
<span id="cb5-64"><a href="#cb5-64" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Beta_Netflix: </span><span class="sc">{</span>mle_betas[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-65"><a href="#cb5-65" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Beta_Prime:   </span><span class="sc">{</span>mle_betas[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-66"><a href="#cb5-66" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Beta_Ads:     </span><span class="sc">{</span>mle_betas[<span class="dv">2</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-67"><a href="#cb5-67" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Beta_Price:   </span><span class="sc">{</span>mle_betas[<span class="dv">3</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-68"><a href="#cb5-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-69"><a href="#cb5-69" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Standard Errors and Confidence Intervals ---</span></span>
<span id="cb5-70"><a href="#cb5-70" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-71"><a href="#cb5-71" aria-hidden="true" tabindex="-1"></a><span class="co"># The 'hess_inv' attribute from scipy.optimize.OptimizeResult is the inverse Hessian of the objective function</span></span>
<span id="cb5-72"><a href="#cb5-72" aria-hidden="true" tabindex="-1"></a><span class="co"># (which is the negative log-likelihood here). For the BFGS method, this directly provides the asymptotic covariance matrix of the MLEs.</span></span>
<span id="cb5-73"><a href="#cb5-73" aria-hidden="true" tabindex="-1"></a>cov_matrix <span class="op">=</span> result.hess_inv</span>
<span id="cb5-74"><a href="#cb5-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-75"><a href="#cb5-75" aria-hidden="true" tabindex="-1"></a><span class="co"># Standard errors are the square root of the diagonal elements of the covariance matrix.</span></span>
<span id="cb5-76"><a href="#cb5-76" aria-hidden="true" tabindex="-1"></a>std_errors <span class="op">=</span> np.sqrt(np.diag(cov_matrix))</span>
<span id="cb5-77"><a href="#cb5-77" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-78"><a href="#cb5-78" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct 95% Confidence Intervals</span></span>
<span id="cb5-79"><a href="#cb5-79" aria-hidden="true" tabindex="-1"></a><span class="co"># For large samples, MLEs are asymptotically normally distributed.</span></span>
<span id="cb5-80"><a href="#cb5-80" aria-hidden="true" tabindex="-1"></a><span class="co"># CI = Estimate +/- Z_alpha/2 * Standard Error</span></span>
<span id="cb5-81"><a href="#cb5-81" aria-hidden="true" tabindex="-1"></a><span class="co"># For a 95% CI, the Z-value (Z_alpha/2 for a two-tailed test) is approximately 1.96.</span></span>
<span id="cb5-82"><a href="#cb5-82" aria-hidden="true" tabindex="-1"></a>z_value <span class="op">=</span> <span class="fl">1.96</span></span>
<span id="cb5-83"><a href="#cb5-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-84"><a href="#cb5-84" aria-hidden="true" tabindex="-1"></a>conf_intervals <span class="op">=</span> []</span>
<span id="cb5-85"><a href="#cb5-85" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(mle_betas)):</span>
<span id="cb5-86"><a href="#cb5-86" aria-hidden="true" tabindex="-1"></a>    lower_bound <span class="op">=</span> mle_betas[i] <span class="op">-</span> z_value <span class="op">*</span> std_errors[i]</span>
<span id="cb5-87"><a href="#cb5-87" aria-hidden="true" tabindex="-1"></a>    upper_bound <span class="op">=</span> mle_betas[i] <span class="op">+</span> z_value <span class="op">*</span> std_errors[i]</span>
<span id="cb5-88"><a href="#cb5-88" aria-hidden="true" tabindex="-1"></a>    conf_intervals.append((lower_bound, upper_bound))</span>
<span id="cb5-89"><a href="#cb5-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-90"><a href="#cb5-90" aria-hidden="true" tabindex="-1"></a><span class="co"># Print results with standard errors and confidence intervals</span></span>
<span id="cb5-91"><a href="#cb5-91" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'Beta_Netflix'</span>, <span class="st">'Beta_Prime'</span>, <span class="st">'Beta_Ads'</span>, <span class="st">'Beta_Price'</span>]</span>
<span id="cb5-92"><a href="#cb5-92" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- MLE Parameters with Standard Errors and 95% Confidence Intervals ---"</span>)</span>
<span id="cb5-93"><a href="#cb5-93" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, name <span class="kw">in</span> <span class="bu">enumerate</span>(param_names):</span>
<span id="cb5-94"><a href="#cb5-94" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">: </span><span class="sc">{</span>mle_betas[i]<span class="sc">:.4f}</span><span class="ss"> (Std Err: </span><span class="sc">{</span>std_errors[i]<span class="sc">:.4f}</span><span class="ss">, 95% CI: [</span><span class="sc">{</span>conf_intervals[i][<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">, </span><span class="sc">{</span>conf_intervals[i][<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">])"</span>)</span>
<span id="cb5-95"><a href="#cb5-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-96"><a href="#cb5-96" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare with true parameters (for mock data scenarios)</span></span>
<span id="cb5-97"><a href="#cb5-97" aria-hidden="true" tabindex="-1"></a>true_betas <span class="op">=</span> np.array([<span class="fl">1.0</span>, <span class="fl">0.5</span>, <span class="op">-</span><span class="fl">0.8</span>, <span class="op">-</span><span class="fl">0.1</span>])</span>
<span id="cb5-98"><a href="#cb5-98" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- True Parameters ---"</span>)</span>
<span id="cb5-99"><a href="#cb5-99" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Beta_Netflix: </span><span class="sc">{</span>true_betas[<span class="dv">0</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-100"><a href="#cb5-100" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Beta_Prime:   </span><span class="sc">{</span>true_betas[<span class="dv">1</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-101"><a href="#cb5-101" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Beta_Ads:     </span><span class="sc">{</span>true_betas[<span class="dv">2</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb5-102"><a href="#cb5-102" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"True Beta_Price:   </span><span class="sc">{</span>true_betas[<span class="dv">3</span>]<span class="sc">:.4f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- MLE Optimization Results ---
  message: Optimization terminated successfully.
  success: True
   status: 0
      fun: 879.8553701757969
        x: [ 9.412e-01  5.016e-01 -7.320e-01 -9.948e-02]
      nit: 14
      jac: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00]
 hess_inv: [[ 1.174e-02  4.981e-03 -2.176e-04 -1.126e-04]
            [ 4.981e-03  8.934e-03  6.285e-04 -1.846e-05]
            [-2.176e-04  6.285e-04  8.491e-03  1.119e-04]
            [-1.126e-04 -1.846e-05  1.119e-04  4.064e-05]]
     nfev: 110
     njev: 22

MLE Beta Parameters:
Beta_Netflix: 0.9412
Beta_Prime:   0.5016
Beta_Ads:     -0.7320
Beta_Price:   -0.0995

--- MLE Parameters with Standard Errors and 95% Confidence Intervals ---
Beta_Netflix: 0.9412 (Std Err: 0.1084, 95% CI: [0.7288, 1.1536])
Beta_Prime: 0.5016 (Std Err: 0.0945, 95% CI: [0.3164, 0.6869])
Beta_Ads: -0.7320 (Std Err: 0.0921, 95% CI: [-0.9126, -0.5514])
Beta_Price: -0.0995 (Std Err: 0.0064, 95% CI: [-0.1120, -0.0870])

--- True Parameters ---
True Beta_Netflix: 1.0000
True Beta_Prime:   0.5000
True Beta_Ads:     -0.8000
True Beta_Price:   -0.1000</code></pre>
</div>
</div>
<p>::::</p>
</section>
<section id="estimation-via-bayesian-methods" class="level2">
<h2 class="anchored" data-anchor-id="estimation-via-bayesian-methods">5. Estimation via Bayesian Methods</h2>
<div id="91dac0b6" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> itertools <span class="im">import</span> product</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Ensure df_prep is defined (from Section 3) ---</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co"># This block is for self-contained execution. In a live notebook, you'd run Section 3 first.</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="cf">try</span>:</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    df_prep.head()</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a><span class="cf">except</span> <span class="pp">NameError</span>:</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"df_prep DataFrame is not defined. Running mock data generation and preparation."</span>)</span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    np.random.seed(<span class="dv">123</span>)</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    random.seed(<span class="dv">123</span>)</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    brand_options <span class="op">=</span> [<span class="st">"N"</span>, <span class="st">"P"</span>, <span class="st">"H"</span>]</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    ad_options <span class="op">=</span> [<span class="st">"Yes"</span>, <span class="st">"No"</span>]</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>    price_options <span class="op">=</span> np.arange(<span class="dv">8</span>, <span class="dv">33</span>, <span class="dv">4</span>)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>    n_peeps <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    n_tasks <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>    n_alts <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    mock_data_list <span class="op">=</span> []</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> resp_id <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_peeps <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> task_id <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_tasks <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>            sampled_profiles <span class="op">=</span> pd.DataFrame(<span class="bu">list</span>(product(brand_options, ad_options, price_options)), columns<span class="op">=</span>[<span class="st">'brand'</span>, <span class="st">'ad'</span>, <span class="st">'price'</span>]).sample(n<span class="op">=</span>n_alts, random_state<span class="op">=</span>resp_id<span class="op">*</span>task_id)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'resp'</span>] <span class="op">=</span> resp_id</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'task'</span>] <span class="op">=</span> task_id</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>            b_util_mock <span class="op">=</span> {<span class="st">"N"</span>: <span class="fl">1.0</span>, <span class="st">"P"</span>: <span class="fl">0.5</span>, <span class="st">"H"</span>: <span class="dv">0</span>}</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>            a_util_mock <span class="op">=</span> {<span class="st">"Yes"</span>: <span class="op">-</span><span class="fl">0.8</span>, <span class="st">"No"</span>: <span class="fl">0.0</span>}</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>            p_util_mock <span class="op">=</span> <span class="kw">lambda</span> p: <span class="op">-</span><span class="fl">0.1</span> <span class="op">*</span> p</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'v_mock'</span>] <span class="op">=</span> sampled_profiles.<span class="bu">apply</span>(</span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>                <span class="kw">lambda</span> row: b_util_mock[row[<span class="st">'brand'</span>]] <span class="op">+</span> a_util_mock[row[<span class="st">'ad'</span>]] <span class="op">+</span> p_util_mock(row[<span class="st">'price'</span>]), axis<span class="op">=</span><span class="dv">1</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'e_mock'</span>] <span class="op">=</span> <span class="op">-</span>np.log(<span class="op">-</span>np.log(np.random.rand(n_alts)))</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'u_mock'</span>] <span class="op">=</span> sampled_profiles[<span class="st">'v_mock'</span>] <span class="op">+</span> sampled_profiles[<span class="st">'e_mock'</span>]</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>            sampled_profiles[<span class="st">'choice'</span>] <span class="op">=</span> (sampled_profiles[<span class="st">'u_mock'</span>] <span class="op">==</span> sampled_profiles[<span class="st">'u_mock'</span>].<span class="bu">max</span>()).astype(<span class="bu">int</span>)</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>            mock_data_list.append(sampled_profiles[[<span class="st">'resp'</span>, <span class="st">'task'</span>, <span class="st">'brand'</span>, <span class="st">'ad'</span>, <span class="st">'price'</span>, <span class="st">'choice'</span>]])</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    conjoint_data <span class="op">=</span> pd.concat(mock_data_list, ignore_index<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>    df_prep <span class="op">=</span> conjoint_data.copy()</span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>    df_prep <span class="op">=</span> pd.get_dummies(df_prep, columns<span class="op">=</span>[<span class="st">'brand'</span>, <span class="st">'ad'</span>], drop_first<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    df_prep.rename(columns<span class="op">=</span>{</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span class="st">'brand_N'</span>: <span class="st">'Netflix'</span>,</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        <span class="st">'brand_P'</span>: <span class="st">'Prime'</span>,</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        <span class="st">'ad_Yes'</span>: <span class="st">'Ads'</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>    }, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    df_prep <span class="op">=</span> df_prep.drop(columns<span class="op">=</span>[<span class="st">'brand_H'</span>, <span class="st">'ad_No'</span>])</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>    cols_to_ensure_numeric <span class="op">=</span> [<span class="st">'Netflix'</span>, <span class="st">'Prime'</span>, <span class="st">'Ads'</span>, <span class="st">'price'</span>, <span class="st">'resp'</span>, <span class="st">'task'</span>, <span class="st">'choice'</span>]</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> col <span class="kw">in</span> cols_to_ensure_numeric:</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>        df_prep[col] <span class="op">=</span> pd.to_numeric(df_prep[col], errors<span class="op">=</span><span class="st">'coerce'</span>)</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>    initial_rows_count <span class="op">=</span> df_prep.shape[<span class="dv">0</span>]</span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    df_prep.dropna(subset<span class="op">=</span>cols_to_ensure_numeric, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> df_prep.shape[<span class="dv">0</span>] <span class="op">&lt;</span> initial_rows_count:</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Warning: Dropped </span><span class="sc">{</span>initial_rows_count <span class="op">-</span> df_prep<span class="sc">.</span>shape[<span class="dv">0</span>]<span class="sc">}</span><span class="ss"> rows due to non-numeric values or NaNs during mock data prep."</span>)</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"df_prep DataFrame prepared from mock data."</span>)</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-likelihood function (re-using from MLE section)</span></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a><span class="co"># beta_vector: [beta_netflix, beta_prime, beta_ads, beta_price]</span></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mnl_log_likelihood(beta_vector, data):</span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.copy() <span class="co"># Create a copy to avoid modifying the original DataFrame</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> data[[<span class="st">'Netflix'</span>, <span class="st">'Prime'</span>, <span class="st">'Ads'</span>, <span class="st">'price'</span>]].values</span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> X.astype(np.float64) <span class="co"># Ensure X is float64 for np.dot</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>    V <span class="op">=</span> np.dot(X, beta_vector)</span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Clip V to prevent extreme values that cause inf/nan in exp(V)</span></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>    V_clipped <span class="op">=</span> np.clip(V, <span class="op">-</span><span class="dv">500</span>, <span class="dv">500</span>) </span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Assign exp_V directly to a new column in the data DataFrame</span></span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>    data[<span class="st">'exp_V'</span>] <span class="op">=</span> np.exp(V_clipped)</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Group by resp and task to get sum of exp(V) for each choice set</span></span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>    sum_exp_V_per_task <span class="op">=</span> data.groupby([<span class="st">'resp'</span>, <span class="st">'task'</span>])[<span class="st">'exp_V'</span>].transform(<span class="st">'sum'</span>)</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add a small constant for numerical stability to prevent division by zero</span></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>    probabilities <span class="op">=</span> data[<span class="st">'exp_V'</span>] <span class="op">/</span> (sum_exp_V_per_task <span class="op">+</span> <span class="fl">1e-9</span>)</span>
<span id="cb7-81"><a href="#cb7-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-82"><a href="#cb7-82" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Add small constant to probabilities before log to avoid log(0) which is -inf</span></span>
<span id="cb7-83"><a href="#cb7-83" aria-hidden="true" tabindex="-1"></a>    log_probabilities <span class="op">=</span> np.log(probabilities <span class="op">+</span> <span class="fl">1e-9</span>) </span>
<span id="cb7-84"><a href="#cb7-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-85"><a href="#cb7-85" aria-hidden="true" tabindex="-1"></a>    total_log_likelihood <span class="op">=</span> np.<span class="bu">sum</span>(np.where(data[<span class="st">'choice'</span>] <span class="op">==</span> <span class="dv">1</span>, log_probabilities, <span class="dv">0</span>))</span>
<span id="cb7-86"><a href="#cb7-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-87"><a href="#cb7-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> total_log_likelihood</span>
<span id="cb7-88"><a href="#cb7-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-89"><a href="#cb7-89" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-prior function</span></span>
<span id="cb7-90"><a href="#cb7-90" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_prior(beta_vector):</span>
<span id="cb7-91"><a href="#cb7-91" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Priors: N(0, 5) for beta_netflix, beta_prime, beta_ads</span></span>
<span id="cb7-92"><a href="#cb7-92" aria-hidden="true" tabindex="-1"></a>    <span class="co"># N(0, 1) for beta_price</span></span>
<span id="cb7-93"><a href="#cb7-93" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-94"><a href="#cb7-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log-PDF for Netflix, Prime, Ads (indices 0, 1, 2)</span></span>
<span id="cb7-95"><a href="#cb7-95" aria-hidden="true" tabindex="-1"></a>    log_prior_binary <span class="op">=</span> norm.logpdf(beta_vector[<span class="dv">0</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">5</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb7-96"><a href="#cb7-96" aria-hidden="true" tabindex="-1"></a>                       norm.logpdf(beta_vector[<span class="dv">1</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">5</span>) <span class="op">+</span> <span class="op">\</span></span>
<span id="cb7-97"><a href="#cb7-97" aria-hidden="true" tabindex="-1"></a>                       norm.logpdf(beta_vector[<span class="dv">2</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb7-98"><a href="#cb7-98" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-99"><a href="#cb7-99" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Log-PDF for Price (index 3)</span></span>
<span id="cb7-100"><a href="#cb7-100" aria-hidden="true" tabindex="-1"></a>    log_prior_price <span class="op">=</span> norm.logpdf(beta_vector[<span class="dv">3</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb7-101"><a href="#cb7-101" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-102"><a href="#cb7-102" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> log_prior_binary <span class="op">+</span> log_prior_price</span>
<span id="cb7-103"><a href="#cb7-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-104"><a href="#cb7-104" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the log-posterior function</span></span>
<span id="cb7-105"><a href="#cb7-105" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> log_posterior(beta_vector, data):</span>
<span id="cb7-106"><a href="#cb7-106" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Check for invalid beta_vector values (e.g., if they are NaN or Inf)</span></span>
<span id="cb7-107"><a href="#cb7-107" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> np.<span class="bu">all</span>(np.isfinite(beta_vector)):</span>
<span id="cb7-108"><a href="#cb7-108" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>np.inf <span class="co"># Return negative infinity if parameters are invalid</span></span>
<span id="cb7-109"><a href="#cb7-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-110"><a href="#cb7-110" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate log-likelihood</span></span>
<span id="cb7-111"><a href="#cb7-111" aria-hidden="true" tabindex="-1"></a>    log_lik <span class="op">=</span> mnl_log_likelihood(beta_vector, data)</span>
<span id="cb7-112"><a href="#cb7-112" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-113"><a href="#cb7-113" aria-hidden="true" tabindex="-1"></a>    <span class="co"># If log_lik is -inf or NaN (e.g., due to probabilities becoming 0 or numerical issues)</span></span>
<span id="cb7-114"><a href="#cb7-114" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> np.isfinite(log_lik):</span>
<span id="cb7-115"><a href="#cb7-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="op">-</span>np.inf</span>
<span id="cb7-116"><a href="#cb7-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-117"><a href="#cb7-117" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate log-prior</span></span>
<span id="cb7-118"><a href="#cb7-118" aria-hidden="true" tabindex="-1"></a>    log_p <span class="op">=</span> log_prior(beta_vector)</span>
<span id="cb7-119"><a href="#cb7-119" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-120"><a href="#cb7-120" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Sum log-likelihood and log-prior to get log-posterior</span></span>
<span id="cb7-121"><a href="#cb7-121" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> log_lik <span class="op">+</span> log_p</span>
<span id="cb7-122"><a href="#cb7-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-123"><a href="#cb7-123" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Metropolis-Hastings MCMC Sampler ---</span></span>
<span id="cb7-124"><a href="#cb7-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-125"><a href="#cb7-125" aria-hidden="true" tabindex="-1"></a><span class="co"># Number of steps</span></span>
<span id="cb7-126"><a href="#cb7-126" aria-hidden="true" tabindex="-1"></a>num_steps <span class="op">=</span> <span class="dv">11000</span></span>
<span id="cb7-127"><a href="#cb7-127" aria-hidden="true" tabindex="-1"></a>burn_in <span class="op">=</span> <span class="dv">1000</span></span>
<span id="cb7-128"><a href="#cb7-128" aria-hidden="true" tabindex="-1"></a>retained_samples <span class="op">=</span> <span class="dv">10000</span> <span class="co"># num_steps - burn_in</span></span>
<span id="cb7-129"><a href="#cb7-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-130"><a href="#cb7-130" aria-hidden="true" tabindex="-1"></a><span class="co"># Initial parameters (can start from MLEs or random values)</span></span>
<span id="cb7-131"><a href="#cb7-131" aria-hidden="true" tabindex="-1"></a>initial_betas_mcmc <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.05</span>], dtype<span class="op">=</span>np.float64) </span>
<span id="cb7-132"><a href="#cb7-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-133"><a href="#cb7-133" aria-hidden="true" tabindex="-1"></a><span class="co"># Proposal distribution standard deviations</span></span>
<span id="cb7-134"><a href="#cb7-134" aria-hidden="true" tabindex="-1"></a>proposal_stds <span class="op">=</span> np.array([np.sqrt(<span class="fl">0.05</span>), np.sqrt(<span class="fl">0.05</span>), np.sqrt(<span class="fl">0.05</span>), np.sqrt(<span class="fl">0.005</span>)], dtype<span class="op">=</span>np.float64)</span>
<span id="cb7-135"><a href="#cb7-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-136"><a href="#cb7-136" aria-hidden="true" tabindex="-1"></a><span class="co"># Storage for samples</span></span>
<span id="cb7-137"><a href="#cb7-137" aria-hidden="true" tabindex="-1"></a>mcmc_samples <span class="op">=</span> []</span>
<span id="cb7-138"><a href="#cb7-138" aria-hidden="true" tabindex="-1"></a>current_betas <span class="op">=</span> initial_betas_mcmc.copy()</span>
<span id="cb7-139"><a href="#cb7-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-140"><a href="#cb7-140" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Starting Metropolis-Hastings MCMC Sampling ---"</span>)</span>
<span id="cb7-141"><a href="#cb7-141" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Total steps: </span><span class="sc">{</span>num_steps<span class="sc">}</span><span class="ss">, Burn-in: </span><span class="sc">{</span>burn_in<span class="sc">}</span><span class="ss">, Retained samples: </span><span class="sc">{</span>retained_samples<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-142"><a href="#cb7-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-143"><a href="#cb7-143" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> step <span class="kw">in</span> <span class="bu">range</span>(num_steps):</span>
<span id="cb7-144"><a href="#cb7-144" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Propose new parameters</span></span>
<span id="cb7-145"><a href="#cb7-145" aria-hidden="true" tabindex="-1"></a>    proposed_betas <span class="op">=</span> current_betas <span class="op">+</span> np.random.normal(loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span>proposal_stds, size<span class="op">=</span><span class="bu">len</span>(current_betas))</span>
<span id="cb7-146"><a href="#cb7-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-147"><a href="#cb7-147" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate log-posterior for current and proposed parameters</span></span>
<span id="cb7-148"><a href="#cb7-148" aria-hidden="true" tabindex="-1"></a>    log_post_current <span class="op">=</span> log_posterior(current_betas, df_prep)</span>
<span id="cb7-149"><a href="#cb7-149" aria-hidden="true" tabindex="-1"></a>    log_post_proposed <span class="op">=</span> log_posterior(proposed_betas, df_prep)</span>
<span id="cb7-150"><a href="#cb7-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-151"><a href="#cb7-151" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate acceptance ratio in log-space</span></span>
<span id="cb7-152"><a href="#cb7-152" aria-hidden="true" tabindex="-1"></a>    log_alpha <span class="op">=</span> log_post_proposed <span class="op">-</span> log_post_current</span>
<span id="cb7-153"><a href="#cb7-153" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-154"><a href="#cb7-154" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Accept or reject the proposed parameters</span></span>
<span id="cb7-155"><a href="#cb7-155" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> log_alpha <span class="op">&gt;=</span> <span class="dv">0</span> <span class="kw">or</span> np.random.rand() <span class="op">&lt;</span> np.exp(log_alpha):</span>
<span id="cb7-156"><a href="#cb7-156" aria-hidden="true" tabindex="-1"></a>        current_betas <span class="op">=</span> proposed_betas</span>
<span id="cb7-157"><a href="#cb7-157" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-158"><a href="#cb7-158" aria-hidden="true" tabindex="-1"></a>    mcmc_samples.append(current_betas.copy()) <span class="co"># Store a copy of the current betas</span></span>
<span id="cb7-159"><a href="#cb7-159" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-160"><a href="#cb7-160" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (step <span class="op">+</span> <span class="dv">1</span>) <span class="op">%</span> <span class="dv">1000</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb7-161"><a href="#cb7-161" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Step </span><span class="sc">{</span>step <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_steps<span class="sc">}</span><span class="ss"> completed. Current betas: </span><span class="sc">{</span>current_betas<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-162"><a href="#cb7-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-163"><a href="#cb7-163" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- MCMC Sampling Complete ---"</span>)</span>
<span id="cb7-164"><a href="#cb7-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-165"><a href="#cb7-165" aria-hidden="true" tabindex="-1"></a><span class="co"># Discard burn-in samples and retain the rest</span></span>
<span id="cb7-166"><a href="#cb7-166" aria-hidden="true" tabindex="-1"></a>posterior_samples_array <span class="op">=</span> np.array(mcmc_samples[burn_in:])</span>
<span id="cb7-167"><a href="#cb7-167" aria-hidden="true" tabindex="-1"></a>posterior_df <span class="op">=</span> pd.DataFrame(posterior_samples_array, columns<span class="op">=</span>[<span class="st">'Beta_Netflix'</span>, <span class="st">'Beta_Prime'</span>, <span class="st">'Beta_Ads'</span>, <span class="st">'Beta_Price'</span>])</span>
<span id="cb7-168"><a href="#cb7-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-169"><a href="#cb7-169" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Visualization: Trace Plot and Histogram ---</span></span>
<span id="cb7-170"><a href="#cb7-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-171"><a href="#cb7-171" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose one parameter to plot (e.g., Beta_Netflix)</span></span>
<span id="cb7-172"><a href="#cb7-172" aria-hidden="true" tabindex="-1"></a>param_to_plot <span class="op">=</span> <span class="st">'Beta_Netflix'</span></span>
<span id="cb7-173"><a href="#cb7-173" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-174"><a href="#cb7-174" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">6</span>))</span>
<span id="cb7-175"><a href="#cb7-175" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-176"><a href="#cb7-176" aria-hidden="true" tabindex="-1"></a><span class="co"># Trace plot</span></span>
<span id="cb7-177"><a href="#cb7-177" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb7-178"><a href="#cb7-178" aria-hidden="true" tabindex="-1"></a>plt.plot(posterior_df[param_to_plot])</span>
<span id="cb7-179"><a href="#cb7-179" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Trace Plot for </span><span class="sc">{</span>param_to_plot<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb7-180"><a href="#cb7-180" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Sample Index'</span>)</span>
<span id="cb7-181"><a href="#cb7-181" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Parameter Value'</span>)</span>
<span id="cb7-182"><a href="#cb7-182" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb7-183"><a href="#cb7-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-184"><a href="#cb7-184" aria-hidden="true" tabindex="-1"></a><span class="co"># Histogram of posterior distribution</span></span>
<span id="cb7-185"><a href="#cb7-185" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb7-186"><a href="#cb7-186" aria-hidden="true" tabindex="-1"></a>sns.histplot(posterior_df[param_to_plot], kde<span class="op">=</span><span class="va">True</span>, bins<span class="op">=</span><span class="dv">30</span>)</span>
<span id="cb7-187"><a href="#cb7-187" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="ss">f'Posterior Distribution of </span><span class="sc">{</span>param_to_plot<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb7-188"><a href="#cb7-188" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">'Parameter Value'</span>)</span>
<span id="cb7-189"><a href="#cb7-189" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">'Density'</span>)</span>
<span id="cb7-190"><a href="#cb7-190" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">True</span>, linestyle<span class="op">=</span><span class="st">'--'</span>, alpha<span class="op">=</span><span class="fl">0.6</span>)</span>
<span id="cb7-191"><a href="#cb7-191" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-192"><a href="#cb7-192" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb7-193"><a href="#cb7-193" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb7-194"><a href="#cb7-194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-195"><a href="#cb7-195" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Report Posterior Means, Standard Deviations, and 95% Credible Intervals ---</span></span>
<span id="cb7-196"><a href="#cb7-196" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-197"><a href="#cb7-197" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Bayesian Posterior Summary Statistics ---"</span>)</span>
<span id="cb7-198"><a href="#cb7-198" aria-hidden="true" tabindex="-1"></a>posterior_summary <span class="op">=</span> posterior_df.describe(percentiles<span class="op">=</span>[<span class="fl">0.025</span>, <span class="fl">0.975</span>]).loc[[<span class="st">'mean'</span>, <span class="st">'std'</span>, <span class="st">'2.5%'</span>, <span class="st">'97.5%'</span>]]</span>
<span id="cb7-199"><a href="#cb7-199" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(posterior_summary)</span>
<span id="cb7-200"><a href="#cb7-200" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-201"><a href="#cb7-201" aria-hidden="true" tabindex="-1"></a><span class="co"># --- Comparison with Maximum Likelihood Approach ---</span></span>
<span id="cb7-202"><a href="#cb7-202" aria-hidden="true" tabindex="-1"></a><span class="co"># To ensure MLE results are always available for comparison, we define them here.</span></span>
<span id="cb7-203"><a href="#cb7-203" aria-hidden="true" tabindex="-1"></a><span class="co"># If you run the MLE section separately, these variables will be overwritten, which is fine.</span></span>
<span id="cb7-204"><a href="#cb7-204" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-205"><a href="#cb7-205" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Calculating MLE results for comparison ---"</span>)</span>
<span id="cb7-206"><a href="#cb7-206" aria-hidden="true" tabindex="-1"></a>initial_betas_mle <span class="op">=</span> np.array([<span class="fl">0.1</span>, <span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.1</span>, <span class="op">-</span><span class="fl">0.05</span>], dtype<span class="op">=</span>np.float64)</span>
<span id="cb7-207"><a href="#cb7-207" aria-hidden="true" tabindex="-1"></a><span class="co"># The mnl_log_likelihood function returns positive log-likelihood for MCMC,</span></span>
<span id="cb7-208"><a href="#cb7-208" aria-hidden="true" tabindex="-1"></a><span class="co"># but minimize needs negative log-likelihood for its objective.</span></span>
<span id="cb7-209"><a href="#cb7-209" aria-hidden="true" tabindex="-1"></a>result_mle <span class="op">=</span> minimize(<span class="kw">lambda</span> b, d: <span class="op">-</span>mnl_log_likelihood(b, d), initial_betas_mle, args<span class="op">=</span>(df_prep,), method<span class="op">=</span><span class="st">'BFGS'</span>)</span>
<span id="cb7-210"><a href="#cb7-210" aria-hidden="true" tabindex="-1"></a>mle_betas <span class="op">=</span> result_mle.x</span>
<span id="cb7-211"><a href="#cb7-211" aria-hidden="true" tabindex="-1"></a>cov_matrix_mle <span class="op">=</span> result_mle.hess_inv</span>
<span id="cb7-212"><a href="#cb7-212" aria-hidden="true" tabindex="-1"></a>std_errors_mle <span class="op">=</span> np.sqrt(np.diag(cov_matrix_mle))</span>
<span id="cb7-213"><a href="#cb7-213" aria-hidden="true" tabindex="-1"></a>z_value <span class="op">=</span> <span class="fl">1.96</span></span>
<span id="cb7-214"><a href="#cb7-214" aria-hidden="true" tabindex="-1"></a>conf_intervals_mle <span class="op">=</span> []</span>
<span id="cb7-215"><a href="#cb7-215" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(mle_betas)):</span>
<span id="cb7-216"><a href="#cb7-216" aria-hidden="true" tabindex="-1"></a>    lower_bound <span class="op">=</span> mle_betas[i] <span class="op">-</span> z_value <span class="op">*</span> std_errors_mle[i]</span>
<span id="cb7-217"><a href="#cb7-217" aria-hidden="true" tabindex="-1"></a>    upper_bound <span class="op">=</span> mle_betas[i] <span class="op">+</span> z_value <span class="op">*</span> std_errors_mle[i]</span>
<span id="cb7-218"><a href="#cb7-218" aria-hidden="true" tabindex="-1"></a>    conf_intervals_mle.append((lower_bound, upper_bound))</span>
<span id="cb7-219"><a href="#cb7-219" aria-hidden="true" tabindex="-1"></a>param_names <span class="op">=</span> [<span class="st">'Beta_Netflix'</span>, <span class="st">'Beta_Prime'</span>, <span class="st">'Beta_Ads'</span>, <span class="st">'Beta_Price'</span>]</span>
<span id="cb7-220"><a href="#cb7-220" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"MLE results obtained for comparison."</span>)</span>
<span id="cb7-221"><a href="#cb7-221" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-222"><a href="#cb7-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-223"><a href="#cb7-223" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Comparison: Bayesian MCMC vs. Maximum Likelihood Estimation ---"</span>)</span>
<span id="cb7-224"><a href="#cb7-224" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Parameter | Bayesian Mean | Bayesian Std | Bayesian 95% CI | MLE Estimate | MLE Std Err | MLE 95% CI"</span>)</span>
<span id="cb7-225"><a href="#cb7-225" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"-----------------------------------------------------------------------------------------------------------------"</span>)</span>
<span id="cb7-226"><a href="#cb7-226" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, name <span class="kw">in</span> <span class="bu">enumerate</span>(param_names):</span>
<span id="cb7-227"><a href="#cb7-227" aria-hidden="true" tabindex="-1"></a>    bayesian_mean <span class="op">=</span> posterior_summary.loc[<span class="st">'mean'</span>, name]</span>
<span id="cb7-228"><a href="#cb7-228" aria-hidden="true" tabindex="-1"></a>    bayesian_std <span class="op">=</span> posterior_summary.loc[<span class="st">'std'</span>, name]</span>
<span id="cb7-229"><a href="#cb7-229" aria-hidden="true" tabindex="-1"></a>    bayesian_ci_lower <span class="op">=</span> posterior_summary.loc[<span class="st">'2.5%'</span>, name]</span>
<span id="cb7-230"><a href="#cb7-230" aria-hidden="true" tabindex="-1"></a>    bayesian_ci_upper <span class="op">=</span> posterior_summary.loc[<span class="st">'97.5%'</span>, name]</span>
<span id="cb7-231"><a href="#cb7-231" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-232"><a href="#cb7-232" aria-hidden="true" tabindex="-1"></a>    mle_estimate <span class="op">=</span> mle_betas[i]</span>
<span id="cb7-233"><a href="#cb7-233" aria-hidden="true" tabindex="-1"></a>    mle_std_err <span class="op">=</span> std_errors_mle[i]</span>
<span id="cb7-234"><a href="#cb7-234" aria-hidden="true" tabindex="-1"></a>    mle_ci_lower <span class="op">=</span> conf_intervals_mle[i][<span class="dv">0</span>]</span>
<span id="cb7-235"><a href="#cb7-235" aria-hidden="true" tabindex="-1"></a>    mle_ci_upper <span class="op">=</span> conf_intervals_mle[i][<span class="dv">1</span>]</span>
<span id="cb7-236"><a href="#cb7-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-237"><a href="#cb7-237" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>name<span class="sc">:&lt;9}</span><span class="ss"> | </span><span class="sc">{</span>bayesian_mean<span class="sc">:13.4f}</span><span class="ss"> | </span><span class="sc">{</span>bayesian_std<span class="sc">:12.4f}</span><span class="ss"> | [</span><span class="sc">{</span>bayesian_ci_lower<span class="sc">:7.4f}</span><span class="ss">, </span><span class="sc">{</span>bayesian_ci_upper<span class="sc">:7.4f}</span><span class="ss">] | </span><span class="sc">{</span>mle_estimate<span class="sc">:12.4f}</span><span class="ss"> | </span><span class="sc">{</span>mle_std_err<span class="sc">:11.4f}</span><span class="ss"> | [</span><span class="sc">{</span>mle_ci_lower<span class="sc">:7.4f}</span><span class="ss">, </span><span class="sc">{</span>mle_ci_upper<span class="sc">:7.4f}</span><span class="ss">]"</span>)</span>
<span id="cb7-238"><a href="#cb7-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-239"><a href="#cb7-239" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- Interpretation ---"</span>)</span>
<span id="cb7-240"><a href="#cb7-240" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"In general, for sufficiently large sample sizes, Bayesian posterior means and standard deviations (and credible intervals) are expected to be similar to MLE estimates and their standard errors (and confidence intervals)."</span>)</span>
<span id="cb7-241"><a href="#cb7-241" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Any notable differences could be due to:"</span>)</span>
<span id="cb7-242"><a href="#cb7-242" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"1. The choice of prior distributions (especially if the prior is very informative)."</span>)</span>
<span id="cb7-243"><a href="#cb7-243" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"2. Insufficient MCMC chain length or burn-in (check trace plots for convergence)."</span>)</span>
<span id="cb7-244"><a href="#cb7-244" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"3. Differences in how standard errors are calculated (asymptotic vs. posterior sample)."</span>)</span>
<span id="cb7-245"><a href="#cb7-245" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"4. Numerical stability issues in the likelihood function for extreme parameter values."</span>)</span>
<span id="cb7-246"><a href="#cb7-246" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"The results from both methods should provide insights into the preference weights for different streaming service attributes."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Starting Metropolis-Hastings MCMC Sampling ---
Total steps: 11000, Burn-in: 1000, Retained samples: 10000
Step 1000/11000 completed. Current betas: [ 1.10066399  0.63248538 -0.64393751 -0.09794073]
Step 2000/11000 completed. Current betas: [ 0.74248622  0.66354872 -0.7527276  -0.10752908]
Step 3000/11000 completed. Current betas: [ 1.0115884   0.49204654 -0.73226032 -0.09578803]
Step 4000/11000 completed. Current betas: [ 0.85711719  0.35929496 -0.8045634  -0.10478445]
Step 5000/11000 completed. Current betas: [ 1.03465998  0.69459888 -0.84064235 -0.09974663]
Step 6000/11000 completed. Current betas: [ 0.88620057  0.51872741 -0.74652068 -0.09219769]
Step 7000/11000 completed. Current betas: [ 1.05791435  0.56012718 -0.56787254 -0.0919589 ]
Step 8000/11000 completed. Current betas: [ 1.08115541  0.58585425 -0.77121125 -0.09913206]
Step 9000/11000 completed. Current betas: [ 0.85241723  0.2998144  -0.70238674 -0.10454084]
Step 10000/11000 completed. Current betas: [ 0.94638304  0.48775865 -0.74193055 -0.09695354]
Step 11000/11000 completed. Current betas: [ 0.84594064  0.56758692 -0.84981676 -0.1028459 ]

--- MCMC Sampling Complete ---</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="hw3_questions_files/figure-html/cell-5-output-2.png" width="1333" height="564" class="figure-img"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- Bayesian Posterior Summary Statistics ---
       Beta_Netflix  Beta_Prime  Beta_Ads  Beta_Price
mean       0.946296    0.500675 -0.741247   -0.100196
std        0.114058    0.117083  0.078775    0.006058
2.5%       0.747114    0.290832 -0.885374   -0.112216
97.5%      1.218240    0.703372 -0.567873   -0.090597

--- Calculating MLE results for comparison ---
MLE results obtained for comparison.

--- Comparison: Bayesian MCMC vs. Maximum Likelihood Estimation ---
Parameter | Bayesian Mean | Bayesian Std | Bayesian 95% CI | MLE Estimate | MLE Std Err | MLE 95% CI
-----------------------------------------------------------------------------------------------------------------
Beta_Netflix |        0.9463 |       0.1141 | [ 0.7471,  1.2182] |       0.9412 |      0.0917 | [ 0.7614,  1.1210]
Beta_Prime |        0.5007 |       0.1171 | [ 0.2908,  0.7034] |       0.5016 |      0.0614 | [ 0.3812,  0.6220]
Beta_Ads  |       -0.7412 |       0.0788 | [-0.8854, -0.5679] |      -0.7320 |      0.1230 | [-0.9731, -0.4909]
Beta_Price |       -0.1002 |       0.0061 | [-0.1122, -0.0906] |      -0.0995 |      0.0070 | [-0.1131, -0.0858]

--- Interpretation ---
In general, for sufficiently large sample sizes, Bayesian posterior means and standard deviations (and credible intervals) are expected to be similar to MLE estimates and their standard errors (and confidence intervals).
Any notable differences could be due to:
1. The choice of prior distributions (especially if the prior is very informative).
2. Insufficient MCMC chain length or burn-in (check trace plots for convergence).
3. Differences in how standard errors are calculated (asymptotic vs. posterior sample).
4. Numerical stability issues in the likelihood function for extreme parameter values.
The results from both methods should provide insights into the preference weights for different streaming service attributes.</code></pre>
</div>
</div>
</section>
<section id="discussion" class="level2">
<h2 class="anchored" data-anchor-id="discussion">6. Discussion</h2>
<p>Observations about Parameter Estimates If we assume the data was not simulated (i.e., it represents real-world conjoint data) and we observe the parameter estimates:</p>
<p>General Observations on Estimates: You would typically examine the sign, magnitude, and statistical significance (or credibility) of each parameter.</p>
<p>Signs: Positive coefficients indicate a preference for that attribute level (e.g., higher utility), while negative coefficients suggest an aversion (lower utility). Magnitude: The absolute magnitude of the coefficient reveals the strength of the preference or aversion. Larger absolute values imply a stronger impact on utility. Significance/Credibility: If the 95% confidence interval (for MLE) or credible interval (for Bayesian) does not include zero, it suggests that the attribute level has a statistically significant or credible impact on utility, indicating the true effect is unlikely to be zero. What does <span class="math inline">\(\beta_{\text{Netflix}} &gt; \beta_{\text{Prime}}\)</span> mean? This implies that, holding all other factors constant (such as price and ad exposure), consumers derive higher utility from Netflix compared to Prime Video. Since Hulu (or the brand_H dummy) was typically set as the reference category with a coefficient of zero, this observation also suggests that consumers prefer Netflix more than Prime Video, and both Netflix and Prime Video are preferred over Hulu (assuming both <span class="math inline">\(\beta_{\text{Netflix}}\)</span> and <span class="math inline">\(\beta_{\text{Prime}}\)</span> are positive and greater than zero). The difference in their magnitudes (<span class="math inline">\(\beta_{\text{Netflix}} - \beta_{\text{Prime}}\)</span>) represents the incremental utility gain from choosing Netflix over Prime Video. For example, if <span class="math inline">\(\beta_{\text{Netflix}} = 1.0\)</span> and <span class="math inline">\(\beta_{\text{Prime}} = 0.5\)</span>, opting for Netflix instead of Prime provides an additional 0.5 units of utility.</p>
<p>Does it make sense that <span class="math inline">\(\beta_{\text{price}}\)</span> is negative? Yes, it makes perfect sense. Price represents a cost to the consumer. A negative coefficient for price indicates that as the price of an alternative increases, the utility derived from that alternative decreases. This aligns with fundamental economic principles of consumer behavior: all else being equal, consumers prefer lower prices. A larger absolute value for <span class="math inline">\(\beta_{\text{price}}\)</span> would imply that consumers are more sensitive to price changes.</p>
<p>Simulating Data and Estimating Parameters for a Multi-Level (Hierarchical) Model A multi-level (also known as random-parameter or hierarchical) model is crucial for analyzing “real-world” conjoint data because it directly accounts for heterogeneity in preferences across individuals. Instead of assuming all respondents share the exact same underlying utility parameters (as in the simple MNL model you’ve implemented), it allows individual-specific parameters to vary according to a distribution (e.g., a normal distribution) across the population.</p>
<p>Here’s a high-level overview of the changes needed to simulate data from and estimate parameters of such a model:</p>
<ol type="1">
<li>Simulating Data for a Multi-Level Model: Individual-Specific Betas: Instead of a single “true” beta_vector for the entire population, you’d first define a population-level mean vector (<span class="math inline">\(\mu_{\beta}\)</span>) and a covariance matrix (<span class="math inline">\(\Sigma_{\beta}\)</span>) for the betas. Sampling Individual Betas: For each simulated respondent (<span class="math inline">\(i\)</span>), you would then draw their individual beta_vector_i from a multivariate normal distribution: <span class="math display">\[\beta_i \sim \mathcal{N}(\mu_{\beta}, \Sigma_{\beta})\]</span> Generating Choices: For each respondent i and each choice task t, you’d use their specific beta_vector_i to calculate the utilities (<span class="math inline">\(V_{ijt} = x_{jt}'\beta_i\)</span>) for all alternatives j in that task. Add extreme value (Gumbel) distributed error terms (<span class="math inline">\(\varepsilon_{ijt}\)</span>) and determine the chosen alternative (choice_ijt) based on the highest total utility (<span class="math inline">\(U_{ijt} = V_{ijt} + \varepsilon_{ijt}\)</span>), similar to your current simulation but personalized by individual betas. Data Structure: The simulated data would maintain a similar observation-level structure (resp, task, attributes, choice), but the underlying beta_vector used to generate each choice would vary by resp.</li>
<li>Estimating Parameters for a Multi-Level Model: Estimating these models is significantly more complex than standard MLE or basic MCMC, often requiring advanced Bayesian methods.</li>
</ol>
<p>Model Formulation:</p>
<p>Likelihood: The likelihood for an individual’s choices, given their specific betas, would remain similar to the MNL likelihood. Priors: You’d need to define priors not only for the individual betas (which are now treated as random variables drawn from a distribution) but also for the hyper-parameters of that distribution—specifically, the mean (<span class="math inline">\(\mu_{\beta}\)</span>) and the covariance matrix (<span class="math inline">\(\Sigma_{\beta}\)</span>) of the population-level beta distribution. Hierarchical Structure: The model explicitly links individual-level parameters to population-level parameters, allowing for “borrowing strength” across individuals while acknowledging individual differences. MCMC Sampler Changes:</p>
<p>Increased Parameter Space: The MCMC algorithm would need to sample not just the mean beta parameters but also the elements of the covariance matrix (<span class="math inline">\(\Sigma_{\beta}\)</span>). For instance, with 4 betas, <span class="math inline">\(\Sigma_{\beta}\)</span> is a <span class="math inline">\(4 \times 4\)</span> matrix, introducing many more parameters (4 variances and 6 covariances) to estimate. More Complex Proposal Distribution: The proposal distribution for sampling the individual beta_i’s and the elements of <span class="math inline">\(\Sigma_{\beta}\)</span> would be more intricate. Specialized MCMC algorithms like Gibbs sampling or more advanced Metropolis-Hastings variants are commonly used, often drawing on techniques like slice sampling or Hamiltonian Monte Carlo (HMC) for greater efficiency, especially when dealing with the covariance matrix. Data Partitioning: The log-likelihood calculation would involve summing log-likelihoods over each individual’s choices, given their currently sampled individual-level betas. Convergence Challenges: Multi-level MCMC models often require longer burn-in periods, more samples, and meticulous tuning of proposal distributions to ensure proper convergence due to the higher dimensionality and interdependencies of parameters. Specialized Software: While possible to code from scratch (as you’ve done with basic MCMC), practitioners typically rely on robust probabilistic programming languages and libraries built for hierarchical modeling, such as: PyMC (Python) Stan (accessible via pystan in Python or rstan in R) JAGS/BUGS (older, but still used)</p>
<p>In essence, building and estimating a multi-level conjoint model involves a significant leap in complexity, moving from a single set of population parameters to a distribution of individual parameters characterized by population-level means and covariances.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>