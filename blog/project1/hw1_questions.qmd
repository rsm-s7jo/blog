---
title: "A Replication of Karlan and List (2007)"
author: "Sunghoon"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes

---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).


The key experimental conditions included: \
- A **standard appeal letter** (control group) \
- A **matching donation letter**, where the organization promised to match donations at ratios of 1:1, 2:1, or 3:1 \
- A **challenge grant letter**, which emphasized reaching a target donation amount before a match would be triggered \

The goal was to examine whether **donors are more likely to give** (and give more) when their donations are matched — and whether the **size of the match ratio** (e.g., 3:1 vs. 1:1) affects this behavior.

Their findings contributed to the literature on charitable giving by showing that **matching gifts significantly increase response rates**, though larger match ratios do not always yield proportionally larger effects.

This project seeks to replicate and explore these results using the original dataset provided by the authors. It will assess the impact of match treatments on both the likelihood and size of donations, using statistical tests and visualizations to mirror the findings of the original 2007 study.


## Data

### Description

_todo: Read the data into R/Python and describe the data_

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::

```{python}
import pandas as pd

df = pd.read_stata("karlan_list_2007.dta")

print(df.shape)
print(df.describe())
```

```{python}

print(df['treatment'].value_counts())
print(df['control'].value_counts())
```

```{python}
print(df.head())
```

### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

#### Variables Tested
To verify the success of the random assignment, I conducted balance checks on two pre-treatment variables:

- mrm2: months since last donation
- freq: number of prior donations

These variables were tested using both t-tests and linear regression.

#### mrm2

```{python}
from scipy import stats

# NaN removal
df_clean = df[['treatment', 'control', 'mrm2']].dropna()

# separate treatment and control groups
treat = df_clean[df_clean['treatment'] == 1]['mrm2']
control = df_clean[df_clean['control'] == 1]['mrm2']

# T-test 
t_stat, p_val = stats.ttest_ind(treat, control, equal_var=False)
print(f"T-test result: t={t_stat:.3f}, p={p_val:.3f}")
```


#### freq

```{python}
import statsmodels.api as sm

# freq: number of prior donations
df_freq = df[['treatment', 'freq']].dropna()
freq_treat = df_freq[df_freq['treatment'] == 1]['freq']
freq_control = df_freq[df_freq['treatment'] == 0]['freq']
t_stat_freq, p_val_freq = stats.ttest_ind(freq_treat, freq_control, equal_var=False)
print(f"T-test (freq): t={t_stat_freq:.3f}, p={p_val_freq:.3f}")

```

#### Linear Regression

```{python}

import statsmodels.formula.api as smf

# Regression
result = smf.ols('mrm2 ~ treatment', data=df_clean).fit()
print(result.summary())
```

```{python}
# Regression
df_freq['intercept'] = 1
model_freq = sm.OLS(df_freq['freq'], df_freq[['intercept', 'treatment']])
result_freq = model_freq.fit()
print(result_freq.summary())
```


#### Result
| Variable | T-test (p-value) | Regression Coefficient | Regression (p-value) | Balanced? |
|----------|------------------|-------------------------|----------------------|-----------|
| mrm2     | 0.905            | 0.0137                  | 0.905                | Yes       |
| freq     | 0.912            | -0.0120                 | 0.912                | Yes       |

\



For both mrm2 and freq, we fail to reject the null hypothesis that the means are equal between the treatment and control groups.
Both the t-tests and linear regressions produce p-values well above the 0.05 threshold, and the treatment coefficients are near zero.

This strongly suggests that the random assignment was successful in producing comparable groups at baseline. There is no evidence that individuals in the treatment group differed systematically in these pre-treatment characteristics.

#### Why This Matters (Table 1 Context) \
Table 1 in Karlan & List (2007) presents these balance checks to demonstrate the integrity of the experimental design.
By showing no significant differences between groups before treatment, the authors reinforce the internal validity of the study: any post-treatment differences in outcomes can reasonably be attributed to the treatment itself.


These balance tests provide strong evidence that randomization worked as intended.
The treatment and control groups appear statistically equivalent on observed baseline characteristics, supporting causal inference in subsequent analyses.

## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 



```{python}
import matplotlib.pyplot as plt

# charity donation ratio
donation_rates = df.groupby('treatment')['gave'].mean()

# bar plot
donation_rates.plot(kind='bar')
plt.xticks([0, 1], ['Control', 'Treatment'], rotation=0)
plt.ylabel('Proportion Donated')
plt.title('Donation Rate by Group')
plt.show()

```

```{python}
import statsmodels.api as sm

# NaN removal
df_clean = df[['treatment', 'gave']].dropna()

# T-test
gave_treat = df_clean[df_clean['treatment'] == 1]['gave']
gave_control = df_clean[df_clean['treatment'] == 0]['gave']
t_stat, p_val = stats.ttest_ind(gave_treat, gave_control, equal_var=False)
print(f"T-test result: t = {t_stat:.3f}, p = {p_val:.3f}")

# linear regression: gave ~ treatment
df_clean['intercept'] = 1
model = sm.OLS(df_clean['gave'], df_clean[['intercept', 'treatment']])
result = model.fit()
print(result.summary())

```



There is a statistically significant difference in donation rates between groups.
The treatment group had a higher likelihood of donating, and the p-value indicates this difference is unlikely to be due to chance.

The regression confirms the t-test: being in the treatment group increases the donation probability by 0.42 percentage points.
Though small in magnitude, this effect is statistically significant, indicating that matched donations encourage giving.


```{python}
import statsmodels.api as sm

# Probit model
probit_model = sm.Probit(df_clean['gave'], df_clean[['intercept', 'treatment']])
probit_result = probit_model.fit()
print(probit_result.summary())
```

The positive and significant coefficient from the probit regression supports the earlier findings:
Being offered a matching donation increases the probability of giving.
This matches Table 3, Column 1 in Karlan & List (2007), confirming the replication.


#### Human Behavior Insight 
These results show that even a small external incentive — like a matching donation — can nudge people toward giving.
It reinforces the idea that donors are influenced not just by personal motivation, but also by context and structure of giving opportunities.

### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.


```{python}
# 1:1 vs 2:1
t1 = df[df['ratio'] == 1]['gave'].dropna()
t2 = df[df['ratio2'] == 1]['gave'].dropna()
t_stat_1_2, p_val_1_2 = stats.ttest_ind(t1, t2, equal_var=False)

# 2:1 vs 3:1
t3 = df[df['ratio3'] == 1]['gave'].dropna()
t_stat_2_3, p_val_2_3 = stats.ttest_ind(t2, t3, equal_var=False)

print(f"1:1 vs 2:1 → t = {t_stat_1_2:.3f}, p = {p_val_1_2:.3f}")
print(f"2:1 vs 3:1 → t = {t_stat_2_3:.3f}, p = {p_val_2_3:.3f}")
```

There is no statistically significant difference in donation rates between the 1:1 and 2:1 match groups, or between 2:1 and 3:1 groups.
These results suggest that increasing the match ratio does not meaningfully affect whether people donate.

```{python}
# 1:1 dummy variable
df['ratio1'] = ((df['ratio'] == 1) & (df['ratio2'] != 1) & (df['ratio3'] != 1)).astype(int)

model = sm.OLS(df['gave'], sm.add_constant(df[['ratio1', 'ratio2', 'ratio3']].fillna(0)))
result = model.fit()
print(result.summary())
```

Controlling for other match types, 2:1 and 3:1 match ratios are statistically significant predictors of giving — and lead to ~0.48–0.49 percentage point increases in donation rate compared to the baseline.
However, the magnitude of the difference between match levels is small and likely not practically meaningful.

```{python}
rate_1_1 = df[df['ratio1'] == 1]['gave'].mean()
rate_2_1 = df[df['ratio2'] == 1]['gave'].mean()
rate_3_1 = df[df['ratio3'] == 1]['gave'].mean()

print(f"2:1 - 1:1 = {rate_2_1 - rate_1_1:.4f}")
print(f"3:1 - 2:1 = {rate_3_1 - rate_2_1:.4f}")

```

While increasing the match ratio leads to slightly higher donation rates, the marginal gains from going beyond 1:1 are extremely small.
This aligns with the paper's "figures suggest" comment — indicating that larger matches might not be more effective in practice.

These results show that although higher match ratios appear to encourage slightly more giving, the differences are tiny and inconsistent.
The data suggest that simply offering a match (vs. no match) matters, but offering bigger matches (e.g., 3:1 instead of 2:1) doesn’t have a clear benefit.
People may be motivated by the presence of a match, but not necessarily its size.

### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.


```{python}
import statsmodels.formula.api as smf
result_amt = smf.ols('amount ~ treatment', data=df).fit()
print(result_amt.summary())
```

Being in the treatment group is associated with an average donation increase of ~$0.15, but this result is not statistically significant at the 5% level (p ≈ 0.06).
This suggests weak evidence that the matching offer may slightly increase giving amounts on average, but the effect is small and uncertain.

```{python}
donors = df[df['gave'] == 1]
result_amt_donors = smf.ols('amount ~ treatment', data=donors).fit()
print(result_amt_donors.summary())
```

Among people who did give, being in the treatment group is associated with a slightly lower donation, but the difference is not statistically significant.
This means the matching offer does not appear to increase the size of donations from those already motivated to give.

```{python}
import matplotlib.pyplot as plt

donors_t = donors[donors['treatment'] == 1]
donors_c = donors[donors['treatment'] == 0]

plt.hist(donors_c['amount'], bins=30, alpha=0.6)
plt.axvline(donors_c['amount'].mean(), color='red', linestyle='dashed', label='Mean')
plt.title("Donation Amounts - Control Group")
plt.legend()
plt.show()

plt.hist(donors_t['amount'], bins=30, alpha=0.6)
plt.axvline(donors_t['amount'].mean(), color='red', linestyle='dashed', label='Mean')
plt.title("Donation Amounts - Treatment Group")
plt.legend()
plt.show()
```

Both treatment and control groups have right-skewed donation distributions (long tail of large donations).
The average donation is marked with a red dashed line on each plot.
Visually, the distributions are very similar, supporting the regression results.

These results suggest that:

- Offering a match may make someone slightly more likely to give,
- But it does not meaningfully affect how much they give.

This implies that match offers work more by encouraging action, not by increasing generosity among existing donors.
In other words: people give because of the match — not more because of the match.

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

```{python}
import numpy as np
import matplotlib.pyplot as plt

# seed
np.random.seed(42)

# difference between 10_000 samples
n_total = 100000
control = np.random.binomial(1, 0.018, n_total)
treatment = np.random.binomial(1, 0.022, 10000)

# slicing
control = control[:10000]

# difference from each sample
differences = treatment - control

# cumulative average
cumulative_avg = np.cumsum(differences) / np.arange(1, 10001)

# plot
plt.plot(cumulative_avg, label='Cumulative Difference')
plt.axhline(0.004, color='red', linestyle='--', label='True Difference (0.004)')
plt.xlabel('Number of Simulations')
plt.ylabel('Cumulative Avg Difference')
plt.title('Law of Large Numbers in Action')
plt.legend()
plt.show()
```

The cumulative average of the donation rate difference converged toward the true difference of 0.004, confirming the Law of Large Numbers in practice.

### Central Limit Theorem


```{python}

import seaborn as sns

sample_sizes = [50, 200, 500, 1000]
true_diff = 0.004

fig, axes = plt.subplots(2, 2, figsize=(12, 8))
axes = axes.flatten()

for i, n in enumerate(sample_sizes):
    avg_diffs = []
    for _ in range(1000):
        c = np.random.binomial(1, 0.018, n)
        t = np.random.binomial(1, 0.022, n)
        avg_diffs.append(np.mean(t) - np.mean(c))
    
    sns.histplot(avg_diffs, kde=True, ax=axes[i], bins=30)
    axes[i].axvline(0, color='black', linestyle='--', label='Zero')
    axes[i].axvline(true_diff, color='red', linestyle='--', label='True diff = 0.004')
    axes[i].set_title(f'Sample size: {n}')
    axes[i].legend()

plt.tight_layout()
plt.show()
```

As the sample size increased, the distribution of the mean difference became more tightly centered around the true value and more bell-shaped, illustrating the Central Limit Theorem. Zero moved from being near the center (at small n) to clearly in the tail (at larger n), showing the power of sample size in detecting treatment effects.